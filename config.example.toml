[logging]
logging_directory = "data/logs"

[vtt_to_txt]
input_directory = "data/vtt_to_txt/_input"
output_directory = "data/vtt_to_txt/_output"

[ner_workflow]
input_directory = "data/ner_workflow/_input"
output_directory = "data/ner_workflow/_output" 
ner_batch_size = 15
ner_threshold = 0.7
llm_max_new_tokens = 10000
entity_linking_file = "data/ner-workflow/entites.csv"
entity_linking_theshold = 80

[vtt_anonymization]
input_directory_vtt = "data/vtt_anonymization/_input_vtt"
input_directory_json = "data/vtt_anonymization/_input_json"
output_directory = "data/vtt_anonymization/_output"

vtt_replacements = [
  { pattern = "_", replacement = "" },
  { pattern = "„", replacement = "" },
  { pattern = "“", replacement = "" },
  { pattern = "\"", replacement = "" },
  { pattern = "\\<i\\>", replacement = "" },
  { pattern = "(?:.*\\n){3}.*\\(\\.\\.\\.\\?\\).*", replacement = "" },
  { pattern = "\\(", replacement = "" },
  { pattern = "\\?\\)", replacement = "" },
  { pattern = "\\n{3,}", replacement = "\\n\\n" },
  { pattern = "(?:.*\\n){0,3}.*\\bXXX\\b.*\\n?", replacement = "" },
  { pattern = "(?:.*\\n){0,3}.*<.*\\n?", replacement = "" },
  { pattern = "> (?=[a-zA-Z])", replacement = "" }
]

[dataset_creator]
input_directory_vtt = "data/dataset_creator/_input_vtt"
input_directory_wav = "data/dataset_creator/_input_wav"
output_directory = "data/dataset_creator/_output"
offset = -0.075

[dataset_merger]
input_directory = "data/dataset_merger/_input"
output_directory = "data/dataset_merger/_output"
merged_dataset_name = "merged_dataset_example"

[hdf5_converter]
input_directory = "data/hdf5_converter/_input"
output_directory = "data/hdf5_converter/_output"      
batch_size = "400"       
threads = "16" 
shard_size = "8192"
train_ratio = "0.8"
val_ratio = "0.1"
test_ration = "0.1"
random_seed = "1337"

[dataset_test]
input_directory = "data/dataset_test/_input"